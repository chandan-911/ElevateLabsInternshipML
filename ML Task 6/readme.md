# ğŸŒ¸ K-Nearest Neighbors (KNN) Classification on Iris Dataset

## ğŸ¯ Objective
This project, part of the **AI & ML Internship (Task 6)**, applies the **K-Nearest Neighbors (KNN)** algorithm to the Iris dataset to predict flower species based on sepal and petal measurements. The analysis includes:

- Data preprocessing & normalization  
- Training KNN models with different K values  
- Accuracy evaluation & confusion matrix generation  
- Visualization of decision boundaries to understand KNN behavior

---

## ğŸ“Š Dataset Overview
The **Iris dataset (`Iris.csv`)** consists of **150** flower samples with the following attributes:

| Feature            | Description                            |
|--------------------|----------------------------------------|
| `SepalLengthCm`    | Sepal length in cm                     |
| `SepalWidthCm`     | Sepal width in cm                      |
| `PetalLengthCm`    | Petal length in cm                     |
| `PetalWidthCm`     | Petal width in cm                      |
| `Species`          | Iris-setosa, Iris-versicolor, Iris-virginica |
| `Id`               | Unique identifier (dropped)            |

---

## ğŸ› ï¸ Tools & Libraries
- ğŸ“š **Pandas** â€“ Data handling & preprocessing  
- ğŸ“¦ **Scikit-learn** â€“ Model training, scaling, and evaluation  
- ğŸ“ˆ **Matplotlib & Seaborn** â€“ Visualization  
- â˜ï¸ **Google Colab** â€“ Execution environment  
- ğŸ **Python** â€“ Programming language

---

## ğŸ” Methodology

### âœ… 1. Data Cleaning
- Removed the `Id` column
- Confirmed no missing values
- Applied `StandardScaler` for feature normalization

### ğŸ¤– 2. Model Training
- Split data: **70% training / 30% testing**
- Trained KNN models with: **K = [1, 3, 5, 7, 9, 11, 15]**

### ğŸ“ 3. Evaluation
- Accuracy measured for each K value
- Confusion matrices created for error analysis

### ğŸ§  4. Visualizations
- ğŸ“‰ **Accuracy Plot**: Accuracy vs. K  
- ğŸ”¢ **Confusion Matrices**: K=1 to K=15  
- ğŸŒˆ **Decision Boundaries**: For K=1, 5, 15 using `PetalLengthCm` & `PetalWidthCm`

---

## ğŸ“ Project Files

| File                                | Description                                       |
|-------------------------------------|---------------------------------------------------|
| `iris_knn_classification.ipynb`     | Complete Jupyter Notebook                         |
| `Iris.csv`                          | Input dataset                                     |

---

## ğŸ“Œ Key Observations
- ğŸ”¹ **Accuracy**: Peaks around **K=5 to K=11**, typically **>95%**
- ğŸ”¹ **Confusion**: Minor misclassification between *versicolor* and *virginica*
- ğŸ”¹ **Boundaries**:  
  - **K=1**: Overfits with jagged boundaries  
  - **K=15**: Smooth, generalized regions

---

## ğŸ’¡ Feature-Level Inferences
- ğŸŒŸ `PetalLengthCm` & `PetalWidthCm` are the most informative features
- âš–ï¸ Normalization is critical to avoid scale dominance
- ğŸ“ Best performance observed with **K between 5â€“9**

---

## â–¶ï¸ How to Run

1. Open ğŸ”— [Google Colab](https://colab.research.google.com/)
2. Upload the following:
   - `iris_knn_classification.ipynb`
   - `Iris.csv`
3. Run all cells to:
   - Preprocess data
   - Train & evaluate KNN models
   - Generate outputs: accuracy plot, confusion matrices, and decision boundaries
4. ğŸ“¦ Download the `outputs` folder for submission

---

## âœ… Submission
This repository contains all necessary files and visualizations for **Task 6** of the AI & ML Internship. It demonstrates effective use of the KNN algorithm for multi-class classification with insightful visual analysis and interpretation.

---

> ğŸ”— *â€œData will talk to you if youâ€™re willing to listen.â€ â€“ Jim Bergeson*
